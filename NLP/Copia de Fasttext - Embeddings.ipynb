{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"r-mpXuyJT9UO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648665019901,"user_tz":180,"elapsed":8553,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}},"outputId":"6e416290-357a-4abb-9104-39f282f6381a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","17465344/17464789 [==============================] - 0s 0us/step\n","17473536/17464789 [==============================] - 0s 0us/step\n"]}],"source":["from keras.datasets import imdb\n","from keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","import gensim\n","import os, re, csv, math, codecs\n","num_words=30000\n","(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=num_words+2,)\n","data = np.concatenate((training_data, testing_data), axis=0)\n","targets = np.concatenate((training_targets, testing_targets), axis=0)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jEiPTqOBT_V7","outputId":"3dc47ff3-6c04-45d9-9ccb-92a33cfcee8a","executionInfo":{"status":"ok","timestamp":1648665023865,"user_tz":180,"elapsed":3294,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Categories: [0 1]\n","Number of unique words: 30000\n"]}],"source":["num_words=len(np.unique(np.hstack(data)))\n","print(\"Categories:\", np.unique(targets))\n","print(\"Number of unique words:\", num_words)"]},{"cell_type":"markdown","metadata":{"id":"xSFu-CU_r2QK"},"source":["Agregar este archivo a la carpeta de google drive\n","\n","https://drive.google.com/open?id=1zgSN39uX3OWxGyqwGDypKxQRokE0_njG"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y9mmn9fpUIY6","outputId":"8ad524eb-948a-4180-dcf7-79e9c2313631","executionInfo":{"status":"ok","timestamp":1648665245748,"user_tz":180,"elapsed":204244,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9tOvUY-MUJGH","outputId":"d3775e60-bd5a-4298-b0e8-f0548548d770","executionInfo":{"status":"ok","timestamp":1648665249437,"user_tz":180,"elapsed":298,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Average Review length: 234.75892\n","Standard Deviation: 173\n"]}],"source":["length = [len(i) for i in data]\n","print(\"Average Review length:\", np.mean(length))\n","print(\"Standard Deviation:\", round(np.std(length)))"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jHY8EhzvUdzt","outputId":"efbfddc3-d1d2-4245-be10-3f18b823f83b","executionInfo":{"status":"ok","timestamp":1648665251168,"user_tz":180,"elapsed":252,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Label: 1\n","[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"]}],"source":["print(\"Label:\", targets[0])\n","\n","Label: 1\n","print(data[0])"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4lY7mGCLUf0M","outputId":"7dabfcbd-0e71-4415-d197-9cf71954f0c8","executionInfo":{"status":"ok","timestamp":1648665252780,"user_tz":180,"elapsed":233,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n","1646592/1641221 [==============================] - 0s 0us/step\n","1654784/1641221 [==============================] - 0s 0us/step\n","# big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal measures the hair is big lots of boobs bounce men wear those cut tee shirts that show off their stomachs sickening that men actually wore them and the music is just # trash that plays over and over again in almost every scene there is trashy music boobs and paramedics taking away bodies and the gym still doesn't close for # all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\n"]}],"source":["index = imdb.get_word_index()\n","reverse_index = dict([(value, key) for (key, value) in index.items()]) \n","decoded = \" \".join( [reverse_index.get(i - 3, \"#\") for i in data[1]] )\n","print(decoded)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Yp9nq3GuKL8","outputId":"49b6a1da-62cc-4474-f3e8-1009e07e686a","executionInfo":{"status":"ok","timestamp":1648665457383,"user_tz":180,"elapsed":113511,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["loading word embeddings...\n"]},{"output_type":"stream","name":"stderr","text":["999995it [01:53, 8839.06it/s] "]},{"output_type":"stream","name":"stdout","text":["found 999995 word vectors\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["#load embeddings\n","from tqdm import tqdm\n","EMBEDDING_DIR = \"/content/drive/My Drive/\"\n","print('loading word embeddings...')\n","embeddings_index = {}\n","f = codecs.open(EMBEDDING_DIR+'wiki-news-300d-1M.vec', encoding='utf-8')\n","for line in tqdm(f):\n","    values = line.rstrip().rsplit(' ')\n","    word = values[0]\n","    coefs = np.asarray(values[1:], dtype='float32')\n","    embeddings_index[word] = coefs\n","f.close()\n","print('found %s word vectors' % len(embeddings_index))"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SDEVfp7RY489","outputId":"c5f5edd8-21c7-4693-d0ff-2eb20e984f19","executionInfo":{"status":"ok","timestamp":1648665462436,"user_tz":180,"elapsed":223,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-1.600e-02, -3.000e-04, -1.684e-01,  8.990e-02, -2.000e-02,\n","       -9.300e-03,  4.820e-02, -3.080e-02, -4.510e-02,  6.000e-04,\n","        1.680e-01,  9.650e-02,  3.061e-01, -4.110e-02,  2.960e-02,\n","       -4.630e-02,  3.250e-02, -7.030e-02,  2.220e-02, -1.404e-01,\n","       -2.638e-01, -1.340e-02,  1.277e-01,  1.227e-01,  1.803e-01,\n","       -1.920e-02,  3.530e-02,  1.214e-01,  1.509e-01, -8.610e-02,\n","        9.760e-02, -2.550e-02, -2.760e-02, -1.556e-01, -7.390e-02,\n","        5.430e-02, -6.700e-02, -3.000e-03,  1.515e-01,  6.080e-02,\n","        3.300e-02,  7.470e-02,  9.000e-04,  5.500e-02,  4.800e-03,\n","       -1.320e-02, -2.620e-02, -1.804e-01,  8.050e-02,  4.640e-02,\n","       -1.590e-02, -3.020e-02, -6.785e-01,  1.632e-01,  1.030e-02,\n","        6.550e-02, -8.430e-02,  2.270e-02,  3.350e-02, -3.560e-02,\n","       -6.380e-02, -1.111e-01, -1.700e-03,  9.780e-02,  5.650e-02,\n","       -3.520e-02,  3.950e-02,  1.867e-01,  7.900e-02, -1.234e-01,\n","        1.860e-02,  8.900e-02,  1.631e-01,  7.830e-02,  5.610e-02,\n","        1.447e-01, -2.510e-02,  1.376e-01, -7.900e-03, -2.390e-02,\n","        2.180e-02,  1.494e-01, -1.910e-02, -2.479e-01, -4.990e-02,\n","        5.160e-02, -1.298e-01, -6.480e-02,  2.738e-01,  7.800e-03,\n","        1.710e-02, -3.720e-02,  7.700e-02, -1.167e-01, -3.770e-02,\n","       -4.320e-02,  1.860e-02,  2.090e-02, -1.670e-02,  3.450e-02,\n","       -1.472e-01,  1.220e-02, -5.300e-02, -7.300e-03,  1.029e-01,\n","        2.830e-02, -1.264e-01,  6.600e-03, -5.790e-02,  1.004e-01,\n","       -1.225e-01,  2.470e-02,  8.080e-02, -3.990e-02, -1.080e-02,\n","        4.300e-03,  1.840e-02,  4.880e-02, -1.740e-01, -3.181e-01,\n","       -1.290e-01,  7.830e-02, -1.382e-01,  5.730e-02,  3.250e-02,\n","        1.704e-01, -1.343e-01,  3.700e-03, -3.040e-02,  4.070e-02,\n","        2.318e-01,  3.930e-02,  1.592e-01, -6.020e-02,  2.730e-02,\n","        1.087e-01, -1.890e-02, -1.030e-01, -1.526e-01, -7.830e-02,\n","       -1.257e-01,  1.261e-01, -8.320e-02,  1.561e-01, -2.254e-01,\n","       -1.236e-01, -1.028e-01,  5.830e-02, -2.990e-02,  1.361e-01,\n","       -4.360e-02, -1.580e-02, -1.210e-02,  1.076e-01, -1.770e-02,\n","       -8.890e-02, -5.300e-03, -4.570e-02, -3.170e-02, -1.454e-01,\n","       -1.237e-01, -8.860e-02, -1.620e-02, -1.603e-01,  5.050e-02,\n","        1.500e-01,  6.970e-02, -7.150e-02, -2.450e-02, -9.900e-03,\n","       -1.832e-01,  4.130e-02, -2.510e-02,  8.450e-02,  2.840e-02,\n","       -1.314e-01,  3.021e-01, -1.812e-01, -7.380e-02, -9.990e-02,\n","       -2.980e-02,  1.508e-01, -4.430e-02,  1.709e-01, -5.490e-02,\n","       -1.333e-01, -4.600e-03,  3.950e-02, -2.540e-01, -6.960e-02,\n","        1.900e-02, -4.140e-02,  7.290e-02,  5.560e-02, -9.210e-02,\n","        9.860e-02,  4.900e-03, -1.271e-01,  9.580e-02, -1.140e-01,\n","       -2.240e-02,  2.000e-02, -1.040e-02, -1.110e-02,  6.400e-03,\n","        6.190e-02, -1.497e-01, -1.185e-01,  5.540e-02,  3.960e-02,\n","        3.090e-02,  3.950e-02, -8.760e-02, -3.060e-02, -1.778e-01,\n","        1.257e-01, -1.570e-01,  1.452e-01, -1.522e-01,  9.800e-03,\n","        9.930e-02, -4.600e-03,  5.230e-02, -9.850e-02,  8.320e-02,\n","       -2.352e-01,  2.050e-02,  1.426e-01, -8.500e-03, -3.160e-02,\n","       -2.550e-02,  6.850e-02,  3.141e-01, -6.370e-02,  7.050e-02,\n","       -1.557e-01, -2.177e-01,  1.380e-02, -2.602e-01,  4.350e-02,\n","       -1.156e-01, -1.420e-02, -1.423e-01, -2.142e-01, -2.310e-02,\n","       -7.290e-02,  1.277e-01, -1.052e-01, -1.444e-01,  4.128e-01,\n","        1.017e-01, -1.077e-01,  7.220e-02, -6.290e-02, -9.490e-02,\n","       -1.079e-01, -6.310e-02, -3.890e-02, -3.510e-02,  9.920e-02,\n","        2.050e-02,  2.151e-01,  9.770e-02, -3.590e-02, -4.316e-01,\n","        1.129e-01, -1.438e-01,  5.300e-03, -1.333e-01, -1.541e-01,\n","        6.910e-02,  1.150e-01, -5.660e-02, -5.000e-03,  1.207e-01,\n","       -6.110e-02, -4.740e-02, -1.151e-01, -2.870e-02,  1.378e-01,\n","       -7.290e-02, -2.170e-02,  1.108e-01,  2.770e-02, -2.010e-02,\n","       -2.236e-01, -1.250e-02, -6.930e-02,  2.340e-02, -2.140e-02,\n","        6.940e-02, -5.070e-02, -5.490e-02, -9.270e-02,  7.020e-02,\n","        1.719e-01, -1.370e-02,  6.800e-03,  1.336e-01,  2.860e-02],\n","      dtype=float32)"]},"metadata":{},"execution_count":10}],"source":["embeddings_index[\"car\"]"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"DlY6kxXlUv_b","executionInfo":{"status":"ok","timestamp":1648665464009,"user_tz":180,"elapsed":215,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"outputs":[],"source":["embed_dim=300\n","embedding_matrix=np.zeros([num_words+4,embed_dim])\n","for word, idx in index.items():\n","  if idx <= num_words and word in embeddings_index:\n","    embedding_matrix[idx+3,:]=embeddings_index[word]"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"_HdJ8KrrZszC","executionInfo":{"status":"ok","timestamp":1648665465378,"user_tz":180,"elapsed":3,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"outputs":[],"source":["maxlen=1000"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"6r9jiL4QarNw","executionInfo":{"status":"ok","timestamp":1648665467324,"user_tz":180,"elapsed":865,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"outputs":[],"source":["data = pad_sequences(data,maxlen=maxlen)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OiL4twmwas3F","outputId":"8fd7ba7e-60cf-4b28-cbe2-76ed381c8efd","executionInfo":{"status":"ok","timestamp":1648665468999,"user_tz":180,"elapsed":304,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1000"]},"metadata":{},"execution_count":14}],"source":["len(data[0])"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XoPdGTyaaudk","outputId":"c8dfdc40-d137-4967-ee9c-ec86d3080469","executionInfo":{"status":"ok","timestamp":1648665469831,"user_tz":180,"elapsed":378,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1000"]},"metadata":{},"execution_count":15}],"source":["len(data[1])"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"H9HdnsE2awBy","executionInfo":{"status":"ok","timestamp":1648665470134,"user_tz":180,"elapsed":3,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"outputs":[],"source":["data=np.array(data)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ri0xt9ueaxlK","outputId":"6429a9f0-61df-4b68-e1ae-5af3b994b808","executionInfo":{"status":"ok","timestamp":1648665470818,"user_tz":180,"elapsed":3,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50000, 1000)"]},"metadata":{},"execution_count":17}],"source":["data.shape"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CjoQz25NazxB","outputId":"f20609c6-bc69-4a54-e856-3c37dd0fd8db","executionInfo":{"status":"ok","timestamp":1648665498384,"user_tz":180,"elapsed":515,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_1 (Embedding)     (None, 1000, 300)         9001200   \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 1000, 64)          134464    \n","                                                                 \n"," max_pooling1d_1 (MaxPooling  (None, 500, 64)          0         \n"," 1D)                                                             \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 500, 128)          57472     \n","                                                                 \n"," global_max_pooling1d_1 (Glo  (None, 128)              0         \n"," balMaxPooling1D)                                                \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                4128      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 9,197,297\n","Trainable params: 196,097\n","Non-trainable params: 9,001,200\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]}],"source":["from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout, Dense\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras import optimizers\n","nb_words=num_words+4\n","num_filters=64\n","model = Sequential()\n","model.add(Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=maxlen, trainable=False))\n","model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n","model.add(MaxPooling1D(2))\n","model.add(Conv1D(num_filters*2, 7, activation='relu', padding='same'))\n","model.add(GlobalMaxPooling1D())\n","model.add(Dropout(0.5))\n","model.add(Dense(32, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))  #multi-label (k-hot encoding)\n","\n","adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n","model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n","model.summary()"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fnkm8psrbO3A","outputId":"1a8dff70-7b66-47ba-99ea-a11e639c638d","executionInfo":{"status":"ok","timestamp":1648666245378,"user_tz":180,"elapsed":743221,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","1250/1250 [==============================] - 47s 29ms/step - loss: 0.3956 - accuracy: 0.8138 - val_loss: 0.2760 - val_accuracy: 0.8808\n","Epoch 2/20\n","1250/1250 [==============================] - 37s 30ms/step - loss: 0.2804 - accuracy: 0.8838 - val_loss: 0.2482 - val_accuracy: 0.8964\n","Epoch 3/20\n","1250/1250 [==============================] - 35s 28ms/step - loss: 0.2328 - accuracy: 0.9071 - val_loss: 0.2382 - val_accuracy: 0.9020\n","Epoch 4/20\n","1250/1250 [==============================] - 37s 30ms/step - loss: 0.1947 - accuracy: 0.9240 - val_loss: 0.2462 - val_accuracy: 0.9024\n","Epoch 5/20\n","1250/1250 [==============================] - 35s 28ms/step - loss: 0.1611 - accuracy: 0.9391 - val_loss: 0.2421 - val_accuracy: 0.9029\n","Epoch 6/20\n","1250/1250 [==============================] - 36s 28ms/step - loss: 0.1345 - accuracy: 0.9500 - val_loss: 0.2621 - val_accuracy: 0.9022\n","Epoch 7/20\n","1250/1250 [==============================] - 38s 30ms/step - loss: 0.1111 - accuracy: 0.9598 - val_loss: 0.3009 - val_accuracy: 0.8974\n","Epoch 8/20\n","1250/1250 [==============================] - 35s 28ms/step - loss: 0.0902 - accuracy: 0.9665 - val_loss: 0.3242 - val_accuracy: 0.8943\n","Epoch 9/20\n","1250/1250 [==============================] - 35s 28ms/step - loss: 0.0782 - accuracy: 0.9711 - val_loss: 0.3522 - val_accuracy: 0.8922\n","Epoch 10/20\n","1250/1250 [==============================] - 35s 28ms/step - loss: 0.0695 - accuracy: 0.9738 - val_loss: 0.3644 - val_accuracy: 0.8948\n","Epoch 11/20\n","1250/1250 [==============================] - 35s 28ms/step - loss: 0.0598 - accuracy: 0.9780 - val_loss: 0.3975 - val_accuracy: 0.8943\n","Epoch 12/20\n","1250/1250 [==============================] - 35s 28ms/step - loss: 0.0499 - accuracy: 0.9812 - val_loss: 0.3779 - val_accuracy: 0.8949\n","Epoch 13/20\n","1250/1250 [==============================] - 35s 28ms/step - loss: 0.0484 - accuracy: 0.9822 - val_loss: 0.4485 - val_accuracy: 0.8951\n","Epoch 14/20\n","1250/1250 [==============================] - 37s 30ms/step - loss: 0.0420 - accuracy: 0.9842 - val_loss: 0.4918 - val_accuracy: 0.8918\n","Epoch 15/20\n","1250/1250 [==============================] - 37s 30ms/step - loss: 0.0385 - accuracy: 0.9860 - val_loss: 0.4873 - val_accuracy: 0.8963\n","Epoch 16/20\n","1250/1250 [==============================] - 35s 28ms/step - loss: 0.0367 - accuracy: 0.9866 - val_loss: 0.5563 - val_accuracy: 0.8923\n","Epoch 17/20\n","1250/1250 [==============================] - 35s 28ms/step - loss: 0.0339 - accuracy: 0.9875 - val_loss: 0.5032 - val_accuracy: 0.8903\n","Epoch 18/20\n","1250/1250 [==============================] - 35s 28ms/step - loss: 0.0352 - accuracy: 0.9862 - val_loss: 0.5327 - val_accuracy: 0.8963\n","Epoch 19/20\n","1250/1250 [==============================] - 35s 28ms/step - loss: 0.0281 - accuracy: 0.9895 - val_loss: 0.6336 - val_accuracy: 0.8923\n","Epoch 20/20\n","1250/1250 [==============================] - 37s 30ms/step - loss: 0.0270 - accuracy: 0.9905 - val_loss: 0.6075 - val_accuracy: 0.8905\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fd0facd2a10>"]},"metadata":{},"execution_count":20}],"source":["model.fit(data,targets,batch_size=32,epochs=20,validation_split=0.2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":251},"id":"WymZVTH8b4lQ","outputId":"14d43313-7f02-4faa-dd58-1d30102c9f95"},"outputs":[{"data":{"text/plain":["array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n","         0.        ,  0.        ],\n","       [ 0.08007812,  0.10498047,  0.04980469, ...,  0.00366211,\n","         0.04760742, -0.06884766],\n","       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n","         0.        ,  0.        ],\n","       ...,\n","       [ 0.13378906,  0.1640625 , -0.17382812, ..., -0.25585938,\n","        -0.11669922,  0.08984375],\n","       [-0.12353516,  0.21777344, -0.578125  , ...,  0.12695312,\n","         0.20507812, -0.00543213],\n","       [-0.2265625 , -0.05151367,  0.14941406, ..., -0.19238281,\n","         0.01190186, -0.06542969]])"]},"execution_count":58,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["embedding_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wCaQWMIVdSiI"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","name":"Copia de Fasttext - Embeddings.ipynb","provenance":[{"file_id":"https://github.com/deeplearning-itba/NLP-Embeddings/blob/master/04-Fasttext_Embeddings.ipynb","timestamp":1648664863056}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":0}