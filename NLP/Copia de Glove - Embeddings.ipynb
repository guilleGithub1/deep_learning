{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copia de Glove - Embeddings.ipynb","provenance":[{"file_id":"https://github.com/deeplearning-itba/NLP-Embeddings/blob/master/03-Glove_Embeddings.ipynb","timestamp":1648663613996}],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"r-mpXuyJT9UO","outputId":"53e60d14-63e5-4f07-8880-8a6486bfc9d9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648664119343,"user_tz":180,"elapsed":8749,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["from keras.datasets import imdb\n","from keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","import gensim\n","import os, re, csv, math, codecs\n","num_words=30000\n","(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=num_words+2,)\n","data = np.concatenate((training_data, testing_data), axis=0)\n","targets = np.concatenate((training_targets, testing_targets), axis=0)"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","17465344/17464789 [==============================] - 0s 0us/step\n","17473536/17464789 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","metadata":{"id":"jEiPTqOBT_V7","outputId":"d6d2c968-79c8-4352-a36c-850a0033ae38","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648664121191,"user_tz":180,"elapsed":1862,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["num_words=len(np.unique(np.hstack(data)))\n","print(\"Categories:\", np.unique(targets))\n","print(\"Number of unique words:\", num_words)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Categories: [0 1]\n","Number of unique words: 30000\n"]}]},{"cell_type":"markdown","metadata":{"id":"xSFu-CU_r2QK"},"source":["Agregar este archivo a la carpeta de google drive\n","\n","https://drive.google.com/open?id=1jJ20oNZIysi-V-iORAE0eEZq4LhuWxUW"]},{"cell_type":"code","metadata":{"id":"Y9mmn9fpUIY6","outputId":"df9a8118-8aa3-43dc-d9c3-4d1904c04148","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648664209032,"user_tz":180,"elapsed":24346,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"9tOvUY-MUJGH","outputId":"5a54f97a-3c67-40fe-b079-f0d3ef6aee62","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648664212770,"user_tz":180,"elapsed":485,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["length = [len(i) for i in data]\n","print(\"Average Review length:\", np.mean(length))\n","print(\"Standard Deviation:\", round(np.std(length)))"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Average Review length: 234.75892\n","Standard Deviation: 173\n"]}]},{"cell_type":"code","metadata":{"id":"jHY8EhzvUdzt","outputId":"dfb79bed-6cea-4c8e-a4dc-e55583bede16","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648664215155,"user_tz":180,"elapsed":4,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["print(\"Label:\", targets[0])\n","\n","Label: 1\n","print(data[0])"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Label: 1\n","[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"]}]},{"cell_type":"code","metadata":{"id":"4lY7mGCLUf0M","outputId":"55fa5edb-f9ae-4f2f-ff5d-014aecc4bf76","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648664217620,"user_tz":180,"elapsed":791,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["index = imdb.get_word_index()\n","reverse_index = dict([(value, key) for (key, value) in index.items()]) \n","decoded = \" \".join( [reverse_index.get(i - 3, \"#\") for i in data[1]] )\n","print(decoded)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n","1646592/1641221 [==============================] - 0s 0us/step\n","1654784/1641221 [==============================] - 0s 0us/step\n","# big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal measures the hair is big lots of boobs bounce men wear those cut tee shirts that show off their stomachs sickening that men actually wore them and the music is just # trash that plays over and over again in almost every scene there is trashy music boobs and paramedics taking away bodies and the gym still doesn't close for # all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\n"]}]},{"cell_type":"code","metadata":{"id":"8Yp9nq3GuKL8","outputId":"c59d972d-004b-4e6d-b544-5c72d19fc8dd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648664262501,"user_tz":180,"elapsed":19906,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["#load embeddings\n","EMBEDDING_DIR = \"/content/drive/My Drive/\"\n","print('loading word embeddings...')\n","embeddings_index = {}\n","f = codecs.open(EMBEDDING_DIR+'glove.6B.100d.txt', encoding='utf-8')\n","for line in f:\n","    values = line.rstrip().rsplit(' ')\n","    word = values[0]\n","    coefs = np.asarray(values[1:], dtype='float32')\n","    embeddings_index[word] = coefs\n","f.close()\n","print('found %s word vectors' % len(embeddings_index))"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["loading word embeddings...\n","found 400000 word vectors\n"]}]},{"cell_type":"code","metadata":{"id":"SDEVfp7RY489","outputId":"58ee0ccc-237e-4ab0-b248-985405e1ee89","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648664266768,"user_tz":180,"elapsed":424,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["embeddings_index[\"car\"]"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.1684  , -0.53827 ,  0.31155 , -0.53218 ,  0.26678 , -0.13638 ,\n","        0.36621 ,  0.68383 ,  0.77726 ,  0.68049 ,  0.69137 ,  0.2103  ,\n","        0.091065,  0.24845 , -0.16157 ,  0.46291 , -0.1503  ,  0.2562  ,\n","       -0.1199  ,  0.5913  ,  1.0351  , -0.2052  ,  0.30244 , -0.34101 ,\n","        0.6326  , -0.31603 , -0.9959  , -0.33583 ,  0.25161 ,  0.10323 ,\n","        0.019611,  0.54893 , -0.33433 ,  0.29617 ,  0.41218 ,  0.4207  ,\n","        0.25775 ,  0.12709 ,  0.80269 ,  0.61944 ,  0.54316 , -0.5941  ,\n","        0.87551 , -0.063686, -0.29117 ,  0.61609 ,  0.33376 ,  0.14488 ,\n","       -0.039021, -1.1849  , -0.45951 ,  0.15631 , -0.50818 ,  1.2357  ,\n","        0.30965 , -1.958   , -1.1872  ,  1.2027  ,  2.1138  ,  0.083629,\n","        0.54319 ,  0.78883 ,  0.35416 ,  0.87736 ,  0.54007 , -0.10454 ,\n","        0.075371, -0.45727 , -0.27466 ,  0.11838 , -0.49412 , -0.61325 ,\n","        0.071519, -0.57665 ,  0.21371 ,  0.62137 ,  1.4404  , -0.34033 ,\n","       -0.89958 , -0.69605 ,  0.74058 ,  0.52105 , -0.19224 , -0.20366 ,\n","       -0.22409 , -0.3708  , -0.34663 , -0.86018 , -0.89182 , -0.43871 ,\n","        0.19424 ,  0.17073 ,  0.43663 , -0.11295 , -0.51156 ,  0.34186 ,\n","       -0.10274 ,  0.39684 ,  1.734   , -0.70787 ], dtype=float32)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"DlY6kxXlUv_b","executionInfo":{"status":"ok","timestamp":1648664268795,"user_tz":180,"elapsed":3,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["embed_dim=100\n","embedding_matrix=np.zeros([num_words+4,embed_dim])\n","for word, idx in index.items():\n","  if idx <= num_words and word in embeddings_index:\n","    embedding_matrix[idx+3,:]=embeddings_index[word]"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"_HdJ8KrrZszC","executionInfo":{"status":"ok","timestamp":1648664271467,"user_tz":180,"elapsed":3,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["maxlen=1000"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"6r9jiL4QarNw","executionInfo":{"status":"ok","timestamp":1648664274836,"user_tz":180,"elapsed":1212,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["data = pad_sequences(data,maxlen=maxlen)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"OiL4twmwas3F","outputId":"d5a6c9ba-cd30-4dab-fd21-7839b406001b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648664277400,"user_tz":180,"elapsed":3,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["len(data[0])"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1000"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"XoPdGTyaaudk","outputId":"61163674-5541-4730-9163-2d7b9f028b29","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648664278608,"user_tz":180,"elapsed":3,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["len(data[1])"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1000"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"H9HdnsE2awBy","executionInfo":{"status":"ok","timestamp":1648664281616,"user_tz":180,"elapsed":2,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["data=np.array(data)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"ri0xt9ueaxlK","outputId":"cb7b00b9-8a86-4b38-83cf-05fd08dbc616","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648664283385,"user_tz":180,"elapsed":3,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["data.shape"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50000, 1000)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"CjoQz25NazxB","outputId":"ea151234-b2fa-41e4-a41a-a0f01877ee8e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648664314257,"user_tz":180,"elapsed":1024,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout, Dense\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras import optimizers\n","nb_words=num_words+4\n","num_filters=64\n","model = Sequential()\n","model.add(Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=maxlen, trainable=False))\n","model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n","model.add(MaxPooling1D(2))\n","model.add(Conv1D(num_filters*2, 7, activation='relu', padding='same'))\n","model.add(GlobalMaxPooling1D())\n","model.add(Dropout(0.5))\n","model.add(Dense(32, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))  #multi-label (k-hot encoding)\n","\n","adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n","model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n","model.summary()"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_1 (Embedding)     (None, 1000, 100)         3000400   \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 1000, 64)          44864     \n","                                                                 \n"," max_pooling1d_1 (MaxPooling  (None, 500, 64)          0         \n"," 1D)                                                             \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 500, 128)          57472     \n","                                                                 \n"," global_max_pooling1d_1 (Glo  (None, 128)              0         \n"," balMaxPooling1D)                                                \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                4128      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3,106,897\n","Trainable params: 106,497\n","Non-trainable params: 3,000,400\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]}]},{"cell_type":"code","metadata":{"id":"fnkm8psrbO3A","outputId":"4d14ced4-13d5-49ab-abc0-42aca6eeb7e5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648664825687,"user_tz":180,"elapsed":504135,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["model.fit(data,targets,batch_size=32,epochs=20,validation_split=0.2)"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","1250/1250 [==============================] - 36s 20ms/step - loss: 0.4770 - accuracy: 0.7564 - val_loss: 0.3908 - val_accuracy: 0.8212\n","Epoch 2/20\n","1250/1250 [==============================] - 24s 19ms/step - loss: 0.3472 - accuracy: 0.8487 - val_loss: 0.3520 - val_accuracy: 0.8444\n","Epoch 3/20\n","1250/1250 [==============================] - 24s 20ms/step - loss: 0.3107 - accuracy: 0.8669 - val_loss: 0.3181 - val_accuracy: 0.8597\n","Epoch 4/20\n","1250/1250 [==============================] - 24s 19ms/step - loss: 0.2852 - accuracy: 0.8807 - val_loss: 0.2925 - val_accuracy: 0.8724\n","Epoch 5/20\n","1250/1250 [==============================] - 24s 20ms/step - loss: 0.2597 - accuracy: 0.8927 - val_loss: 0.2883 - val_accuracy: 0.8755\n","Epoch 6/20\n","1250/1250 [==============================] - 24s 20ms/step - loss: 0.2438 - accuracy: 0.9000 - val_loss: 0.2944 - val_accuracy: 0.8755\n","Epoch 7/20\n","1250/1250 [==============================] - 25s 20ms/step - loss: 0.2211 - accuracy: 0.9101 - val_loss: 0.2921 - val_accuracy: 0.8785\n","Epoch 8/20\n","1250/1250 [==============================] - 24s 20ms/step - loss: 0.2047 - accuracy: 0.9172 - val_loss: 0.2963 - val_accuracy: 0.8774\n","Epoch 9/20\n","1250/1250 [==============================] - 24s 20ms/step - loss: 0.1857 - accuracy: 0.9261 - val_loss: 0.2940 - val_accuracy: 0.8760\n","Epoch 10/20\n","1250/1250 [==============================] - 25s 20ms/step - loss: 0.1717 - accuracy: 0.9312 - val_loss: 0.3024 - val_accuracy: 0.8778\n","Epoch 11/20\n","1250/1250 [==============================] - 25s 20ms/step - loss: 0.1546 - accuracy: 0.9381 - val_loss: 0.3167 - val_accuracy: 0.8784\n","Epoch 12/20\n","1250/1250 [==============================] - 24s 20ms/step - loss: 0.1442 - accuracy: 0.9423 - val_loss: 0.3196 - val_accuracy: 0.8749\n","Epoch 13/20\n","1250/1250 [==============================] - 24s 19ms/step - loss: 0.1319 - accuracy: 0.9479 - val_loss: 0.3469 - val_accuracy: 0.8769\n","Epoch 14/20\n","1250/1250 [==============================] - 24s 19ms/step - loss: 0.1214 - accuracy: 0.9518 - val_loss: 0.3897 - val_accuracy: 0.8694\n","Epoch 15/20\n","1250/1250 [==============================] - 25s 20ms/step - loss: 0.1149 - accuracy: 0.9553 - val_loss: 0.3692 - val_accuracy: 0.8773\n","Epoch 16/20\n","1250/1250 [==============================] - 24s 19ms/step - loss: 0.1074 - accuracy: 0.9582 - val_loss: 0.3629 - val_accuracy: 0.8733\n","Epoch 17/20\n","1250/1250 [==============================] - 24s 20ms/step - loss: 0.0994 - accuracy: 0.9607 - val_loss: 0.3992 - val_accuracy: 0.8672\n","Epoch 18/20\n","1250/1250 [==============================] - 24s 19ms/step - loss: 0.0963 - accuracy: 0.9626 - val_loss: 0.4370 - val_accuracy: 0.8697\n","Epoch 19/20\n","1250/1250 [==============================] - 24s 20ms/step - loss: 0.0889 - accuracy: 0.9664 - val_loss: 0.4155 - val_accuracy: 0.8733\n","Epoch 20/20\n","1250/1250 [==============================] - 24s 20ms/step - loss: 0.0845 - accuracy: 0.9675 - val_loss: 0.4210 - val_accuracy: 0.8725\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7ff3271da8d0>"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"WymZVTH8b4lQ","outputId":"14d43313-7f02-4faa-dd58-1d30102c9f95","colab":{"base_uri":"https://localhost:8080/","height":251}},"source":["embedding_matrix"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n","         0.        ,  0.        ],\n","       [ 0.08007812,  0.10498047,  0.04980469, ...,  0.00366211,\n","         0.04760742, -0.06884766],\n","       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n","         0.        ,  0.        ],\n","       ...,\n","       [ 0.13378906,  0.1640625 , -0.17382812, ..., -0.25585938,\n","        -0.11669922,  0.08984375],\n","       [-0.12353516,  0.21777344, -0.578125  , ...,  0.12695312,\n","         0.20507812, -0.00543213],\n","       [-0.2265625 , -0.05151367,  0.14941406, ..., -0.19238281,\n","         0.01190186, -0.06542969]])"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"id":"wCaQWMIVdSiI"},"source":[""],"execution_count":null,"outputs":[]}]}