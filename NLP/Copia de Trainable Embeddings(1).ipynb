{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Copia de Trainable Embeddings.ipynb","provenance":[{"file_id":"https://github.com/deeplearning-itba/NLP-Embeddings/blob/master/01-Trainable%20Embeddings.ipynb","timestamp":1648650232123}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"code","metadata":{"id":"8w8DRjGAHzyG","executionInfo":{"status":"ok","timestamp":1648662464789,"user_tz":180,"elapsed":250,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["# Usar keras 2.2.5\n","# conda install -c conda-forge keras=2.2.5"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"rnLq6p7aHzyK","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"f7d5a7e7-fbf1-4732-e90c-ce2d250ea1c4","executionInfo":{"status":"ok","timestamp":1648662466329,"user_tz":180,"elapsed":5,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["import keras\n","keras.__version__"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.8.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"l6qXmkzsHzyO","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"5cd4d469-bc3e-45eb-fd24-f4e4082e6d3a","executionInfo":{"status":"ok","timestamp":1648662466810,"user_tz":180,"elapsed":4,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["import numpy as np\n","np.__version__"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.21.5'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"0KnibsN1xUk3","executionInfo":{"status":"ok","timestamp":1648662467512,"user_tz":180,"elapsed":1,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["#from keras.datasets import imdb as dataset\n","from tensorflow.keras.datasets import reuters as dataset\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import numpy as np"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AvpowIEOHzyT"},"source":["# Cargamos y analizamos el dataset"]},{"cell_type":"code","metadata":{"id":"n4ra2gF4HzyU","colab":{"base_uri":"https://localhost:8080/"},"outputId":"879e583b-b7bf-42a3-b794-8d51ee8f7977","executionInfo":{"status":"ok","timestamp":1648662469509,"user_tz":180,"elapsed":655,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["# Primer hyperparámetro\n","num_words=30000\n","\n","(training_data, training_targets), (testing_data, testing_targets) = dataset.load_data(num_words=num_words+2)\n","data = np.concatenate((training_data, testing_data), axis=0)\n","targets = np.concatenate((training_targets, testing_targets), axis=0)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n","2113536/2110848 [==============================] - 0s 0us/step\n","2121728/2110848 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","metadata":{"id":"EYWTLfB1xUlI","outputId":"398e363d-97e4-4866-ddf5-f488b55449d5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648662469889,"user_tz":180,"elapsed":383,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["# Tengo dos categorías: Sentimiento positivo (1) o sentimiento negativo (0)\n","num_categories = len(np.unique(targets))\n","print(\"Categories:\", np.unique(targets))\n","# Tengo num_words palabras únicas en el vocabulario\n","print(\"Number of unique words:\", len(np.unique(np.hstack(data))))"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Categories: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45]\n","Number of unique words: 30000\n"]}]},{"cell_type":"code","metadata":{"id":"3lZ-DUxtxUlT","outputId":"d5bc0bd2-2dcc-4f72-b9fd-c5f542886073","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648662469889,"user_tz":180,"elapsed":4,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["# Longitudes promedio de los comentarios de las películas\n","length = [len(i) for i in data]\n","print(\"Average Review length:\", np.mean(length))\n","print(\"Standard Deviation:\", round(np.std(length)))"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Average Review length: 145.96419665122906\n","Standard Deviation: 146\n"]}]},{"cell_type":"markdown","metadata":{"id":"DGeDrxcRHzya"},"source":["# Impresión de comentario preprocesado con su etiqueta"]},{"cell_type":"code","metadata":{"id":"qnT33-acxUlZ","outputId":"74188b87-59d0-4353-c5de-3dff8437a538","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648662471482,"user_tz":180,"elapsed":3,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["# Imprimo cometario i'esimo con su clasificación de sentimiento\n","i = 0\n","print(\"Label:\", targets[i])\n","# Las comentarios ya están preprocesados\n","print(data[i])"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Label: 3\n","[1, 27595, 28842, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n"]}]},{"cell_type":"code","metadata":{"id":"GSVq9thIxUlh","outputId":"fd33f1fa-2344-4597-ecbf-358c9379495f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648662471789,"user_tz":180,"elapsed":4,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["# Bajamos diccionario de palabras a indices\n","index = dataset.get_word_index()\n","print([f'{k}:{v}' for k,v in index.items()][:100])"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n","557056/550378 [==============================] - 0s 0us/step\n","565248/550378 [==============================] - 0s 0us/step\n","['mdbl:10996', 'fawc:16260', 'degussa:12089', 'woods:8803', 'hanging:13796', 'localized:20672', 'sation:20673', 'chanthaburi:20675', 'refunding:10997', 'hermann:8804', 'passsengers:20676', 'stipulate:20677', 'heublein:8352', 'screaming:20713', 'tcby:16261', 'four:185', 'grains:1642', 'broiler:20680', 'wooden:12090', 'wednesday:1220', 'highveld:13797', 'duffour:7593', '0053:20681', 'elections:3914', '270:2563', '271:3551', '272:5113', '273:3552', '274:3400', 'rudman:7975', '276:3401', '277:3478', '278:3632', '279:4309', 'dormancy:9381', 'errors:7247', 'deferred:3086', 'sptnd:20683', 'cooking:8805', 'stratabit:20684', 'designing:16262', 'metalurgicos:20685', 'databank:13798', '300er:20686', 'shocks:20687', 'nawg:7972', 'tnta:20688', 'perforations:20689', 'affiliates:2891', '27p:20690', 'ching:16263', 'china:595', 'wagyu:16264', 'affiliated:3189', 'chino:16265', 'chinh:16266', 'slickline:20692', 'doldrums:13799', 'kids:12092', 'climbed:3028', 'controversy:6693', 'kidd:20693', 'spotty:12093', 'rebel:12639', 'millimetres:9382', 'golden:4007', 'projection:5689', 'stern:12094', \"hudson's:7903\", 'dna:10066', 'dnc:20695', 'hodler:20696', 'lme:2394', 'insolvancy:20697', 'music:13800', 'therefore:1984', 'dns:10998', 'distortions:6959', 'thassos:13801', 'populations:20698', 'meteorologist:8806', 'loss:43', 'exco:9383', 'adventist:20813', 'murchison:16267', 'locked:10999', 'kampala:13802', 'arndt:20699', 'nakasone:1267', 'steinweg:20700', \"india's:3633\", 'wang:3029', 'wane:10067', 'unjust:13803', 'titanium:13804', 'want:850', 'pinto:20701', \"institutes':16268\", 'absolute:7973', 'travel:4677']\n"]}]},{"cell_type":"code","metadata":{"id":"xrmkTbXyHzyf","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6d9421e6-b5f4-4a4e-b627-2250ca772cfe","executionInfo":{"status":"ok","timestamp":1648662472642,"user_tz":180,"elapsed":4,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["# Armo diccionario reverso: de indices a palabras\n","reverse_index = dict([(value, key) for (key, value) in index.items()]) \n","print([f'{k}:{v}' for k,v in reverse_index.items()][:100])"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["['10996:mdbl', '16260:fawc', '12089:degussa', '8803:woods', '13796:hanging', '20672:localized', '20673:sation', '20675:chanthaburi', '10997:refunding', '8804:hermann', '20676:passsengers', '20677:stipulate', '8352:heublein', '20713:screaming', '16261:tcby', '185:four', '1642:grains', '20680:broiler', '12090:wooden', '1220:wednesday', '13797:highveld', '7593:duffour', '20681:0053', '3914:elections', '2563:270', '3551:271', '5113:272', '3552:273', '3400:274', '7975:rudman', '3401:276', '3478:277', '3632:278', '4309:279', '9381:dormancy', '7247:errors', '3086:deferred', '20683:sptnd', '8805:cooking', '20684:stratabit', '16262:designing', '20685:metalurgicos', '13798:databank', '20686:300er', '20687:shocks', '7972:nawg', '20688:tnta', '20689:perforations', '2891:affiliates', '20690:27p', '16263:ching', '595:china', '16264:wagyu', '3189:affiliated', '16265:chino', '16266:chinh', '20692:slickline', '13799:doldrums', '12092:kids', '3028:climbed', '6693:controversy', '20693:kidd', '12093:spotty', '12639:rebel', '9382:millimetres', '4007:golden', '5689:projection', '12094:stern', \"7903:hudson's\", '10066:dna', '20695:dnc', '20696:hodler', '2394:lme', '20697:insolvancy', '13800:music', '1984:therefore', '10998:dns', '6959:distortions', '13801:thassos', '20698:populations', '8806:meteorologist', '43:loss', '9383:exco', '20813:adventist', '16267:murchison', '10999:locked', '13802:kampala', '20699:arndt', '1267:nakasone', '20700:steinweg', \"3633:india's\", '3029:wang', '10067:wane', '13803:unjust', '13804:titanium', '850:want', '20701:pinto', \"16268:institutes'\", '7973:absolute', '4677:travel']\n"]}]},{"cell_type":"code","metadata":{"id":"Lhq6d5MWHzyi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"06696b7b-9e82-4225-fd99-605b20a09ed8","executionInfo":{"status":"ok","timestamp":1648662473415,"user_tz":180,"elapsed":3,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["decoded = \" \".join( [reverse_index.get(i - 3, \"#\") for i in data[1]] )\n","print(data[1])\n","print()\n","print(decoded)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["[1, 3267, 699, 3434, 2295, 56, 16784, 7511, 9, 56, 3906, 1073, 81, 5, 1198, 57, 366, 737, 132, 20, 4093, 7, 19261, 49, 2295, 13415, 1037, 3267, 699, 3434, 8, 7, 10, 241, 16, 855, 129, 231, 783, 5, 4, 587, 2295, 13415, 2, 775, 7, 48, 34, 191, 44, 35, 1795, 505, 17, 12]\n","\n","# generale de banque sa lt genb br and lt heller overseas corp of chicago have each taken 50 pct stakes in factoring company sa belgo factors generale de banque said in a statement it gave no financial details of the transaction sa belgo # turnover in 1986 was 17 5 billion belgian francs reuter 3\n"]}]},{"cell_type":"markdown","metadata":{"id":"RBL_1v2eHzym"},"source":["# Padding y formateo de data para entrenar"]},{"cell_type":"code","metadata":{"id":"HifepVsJxUlo","executionInfo":{"status":"ok","timestamp":1648662475325,"user_tz":180,"elapsed":231,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["# Hyperparametro - Longitud máxima de comentario\n","maxlen=1000"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tb8Mf33exUlu","executionInfo":{"status":"ok","timestamp":1648662475927,"user_tz":180,"elapsed":3,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["data = pad_sequences(data,maxlen=maxlen)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fq-c12e5xUl8","outputId":"fa626db6-5d40-4a0f-d7f1-ef7d291ad970","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648662477355,"user_tz":180,"elapsed":4,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["# Verificamos que todos tengan longitud 1000\n","print(len(data[0]))\n","print(np.array([len(d) for d in data]).var())"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["1000\n","0.0\n"]}]},{"cell_type":"code","metadata":{"id":"jXBIUZaNxUmD","executionInfo":{"status":"ok","timestamp":1648662477355,"user_tz":180,"elapsed":2,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["data=np.array(data)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Gwma-IqxUmK","outputId":"82bc14d0-235f-4f08-bacd-d7f86b492a43","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648662478659,"user_tz":180,"elapsed":4,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["data.shape"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(11228, 1000)"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"8bplIZHWNUXo"},"source":["# Armar una MLP con one-hot encoding para resolver el problema"]},{"cell_type":"code","metadata":{"id":"MQ51AMr2Nbok","executionInfo":{"status":"ok","timestamp":1648662480766,"user_tz":180,"elapsed":399,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["from tensorflow.keras.layers import Dense\n","from tensorflow.keras.models import Sequential"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"YV5eg2fDNdtk","executionInfo":{"status":"ok","timestamp":1648662484096,"user_tz":180,"elapsed":3333,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["# usar maxlen y num_words para calcular la entrada\n","# Utilizar una sola capa\n","model = Sequential()\n","## TODO\n","salida_densa = 46# Completar\n","input_shape = (1000,30000,)# Completar\n","model.add(Dense(salida_densa, input_shape=input_shape, activation='softmax'))"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"PXqCIIv6OWe8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648662484096,"user_tz":180,"elapsed":9,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}},"outputId":"7c8bf719-d930-4f47-8830-ffdecce8b5df"},"source":["model.summary()"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 1000, 46)          1380046   \n","                                                                 \n","=================================================================\n","Total params: 1,380,046\n","Trainable params: 1,380,046\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"h-RLYV5QPBEX"},"source":["## ¿Por que no es viable esta red?\n","La cantidad de parametros es demasiado grande (1,380,046) y podria existir overfitting"]},{"cell_type":"markdown","metadata":{"id":"bnvzV5wiPKjs"},"source":["# Armar una MLP usando Embeddings"]},{"cell_type":"code","metadata":{"id":"ecjdmUczPIVf","executionInfo":{"status":"ok","timestamp":1648662487545,"user_tz":180,"elapsed":2,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["from tensorflow.keras.layers import Embedding, Flatten, Dropout\n","from tensorflow.keras import optimizers"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"OPTlDXslPO0o","executionInfo":{"status":"ok","timestamp":1648662488980,"user_tz":180,"elapsed":379,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["# Cantidad de palabras totales contando las reservadas\n","nb_words=num_words+3\n","# Tamano del embedding. Es un hiperparámetro y puede modificarlo\n","embed_dim=32\n","salida_capa_densa = 46\n","dropout=0.5 # Hiperparámetro\n","\n","model = Sequential()\n","model.add(Embedding(nb_words, embed_dim, input_length=maxlen, trainable=True))\n","model.add(Flatten())\n","model.add(Dropout(dropout))\n","model.add(Dense(salida_capa_densa, activation='softmax'))"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"qTs8XKCLPVqX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648662492487,"user_tz":180,"elapsed":367,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}},"outputId":"cbe7360c-9188-47d8-80d9-eec666800838"},"source":["model.summary()"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 1000, 32)          960096    \n","                                                                 \n"," flatten (Flatten)           (None, 32000)             0         \n","                                                                 \n"," dropout (Dropout)           (None, 32000)             0         \n","                                                                 \n"," dense_1 (Dense)             (None, 46)                1472046   \n","                                                                 \n","=================================================================\n","Total params: 2,432,142\n","Trainable params: 2,432,142\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"J6bygoYSP1PW","executionInfo":{"status":"ok","timestamp":1648662493799,"user_tz":180,"elapsed":2,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["# MODIFIQUE HYPERPARAMS A GUSTO\n","adam = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n","\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"U4tv5kkjPuaj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648662517080,"user_tz":180,"elapsed":21576,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}},"outputId":"95c2f9fc-5e17-4ba1-ed47-a764c78b025f"},"source":["model.fit(data,targets,batch_size=32,epochs=5,validation_split=0.2)"],"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","281/281 [==============================] - 6s 10ms/step - loss: 2.0164 - accuracy: 0.4892 - val_loss: 1.6889 - val_accuracy: 0.5975\n","Epoch 2/5\n","281/281 [==============================] - 2s 9ms/step - loss: 1.2712 - accuracy: 0.6959 - val_loss: 1.3977 - val_accuracy: 0.6794\n","Epoch 3/5\n","281/281 [==============================] - 2s 9ms/step - loss: 0.7554 - accuracy: 0.8303 - val_loss: 1.3021 - val_accuracy: 0.6906\n","Epoch 4/5\n","281/281 [==============================] - 2s 8ms/step - loss: 0.4853 - accuracy: 0.8990 - val_loss: 1.3018 - val_accuracy: 0.6955\n","Epoch 5/5\n","281/281 [==============================] - 2s 8ms/step - loss: 0.3469 - accuracy: 0.9306 - val_loss: 1.3037 - val_accuracy: 0.6941\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8fdaf7ecd0>"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"hNPXfSxWQRI3"},"source":["# Armar una CNN\n","Abajo hay un ejemplo de arquitectur"]},{"cell_type":"code","metadata":{"id":"C8Yi3_A4V5AS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648662517080,"user_tz":180,"elapsed":23,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}},"outputId":"7ac74d31-c2c2-44b7-a93d-baddf4c9336f"},"source":["from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout, Dense\n","from tensorflow.keras import optimizers\n","\n","nb_words=num_words+3\n","embed_dim=32\n","num_filters=64\n","model = Sequential()\n","model.add(Embedding(nb_words, embed_dim, input_length=maxlen, trainable=True))\n","model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n","model.add(MaxPooling1D(2))\n","model.add(Conv1D(num_filters*2, 7, activation='relu', padding='same'))\n","model.add(GlobalMaxPooling1D())\n","model.add(Dropout(0.5))\n","model.add(Dense(num_categories, activation='sigmoid'))\n","\n","model.summary()\n","\n","\n","\n","# _________________________________________________________________\n","# Layer (type)                 Output Shape              Param #   \n","# =================================================================\n","# embedding_12 (Embedding)     (None, 1000, 32)          960096    \n","# _________________________________________________________________\n","# conv1d_7 (Conv1D)            (None, 1000, 64)          14400     \n","# _________________________________________________________________\n","# max_pooling1d_4 (MaxPooling1 (None, 500, 64)           0         \n","# _________________________________________________________________\n","# conv1d_8 (Conv1D)            (None, 500, 128)          57472     \n","# _________________________________________________________________\n","# global_max_pooling1d_4 (Glob (None, 128)               0         \n","# _________________________________________________________________\n","# dropout_4 (Dropout)          (None, 128)               0         \n","# _________________________________________________________________\n","# dense_19 (Dense)             (None, 46)                5934      \n","# ================================================================="],"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_1 (Embedding)     (None, 1000, 32)          960096    \n","                                                                 \n"," conv1d (Conv1D)             (None, 1000, 64)          14400     \n","                                                                 \n"," max_pooling1d (MaxPooling1D  (None, 500, 64)          0         \n"," )                                                               \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 500, 128)          57472     \n","                                                                 \n"," global_max_pooling1d (Globa  (None, 128)              0         \n"," lMaxPooling1D)                                                  \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 46)                5934      \n","                                                                 \n","=================================================================\n","Total params: 1,037,902\n","Trainable params: 1,037,902\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"ssxu2rPVV_d_","executionInfo":{"status":"ok","timestamp":1648662560968,"user_tz":180,"elapsed":301,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}}},"source":["# MODIFIQUE HYPERPARAMS A GUSTO\n","\n","adam = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":[""],"metadata":{"id":"RoF_i7hb_3m8"}},{"cell_type":"code","metadata":{"id":"AzXyAjAvxUmW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648662626022,"user_tz":180,"elapsed":62489,"user":{"displayName":"Guillermo Fridemberg","userId":"01861108116492275748"}},"outputId":"2daf583f-6c2c-4517-bea0-17dcb5b18b2a"},"source":["model.fit(data,targets,batch_size=32,epochs=10,validation_split=0.2)"],"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","281/281 [==============================] - 14s 21ms/step - loss: 2.1021 - accuracy: 0.4722 - val_loss: 1.6915 - val_accuracy: 0.5686\n","Epoch 2/10\n","281/281 [==============================] - 5s 19ms/step - loss: 1.5888 - accuracy: 0.5907 - val_loss: 1.5091 - val_accuracy: 0.6318\n","Epoch 3/10\n","281/281 [==============================] - 5s 19ms/step - loss: 1.3099 - accuracy: 0.6790 - val_loss: 1.3607 - val_accuracy: 0.6781\n","Epoch 4/10\n","281/281 [==============================] - 5s 19ms/step - loss: 1.0949 - accuracy: 0.7290 - val_loss: 1.3199 - val_accuracy: 0.6959\n","Epoch 5/10\n","281/281 [==============================] - 5s 19ms/step - loss: 0.9178 - accuracy: 0.7684 - val_loss: 1.3141 - val_accuracy: 0.7093\n","Epoch 6/10\n","281/281 [==============================] - 5s 19ms/step - loss: 0.7805 - accuracy: 0.8017 - val_loss: 1.3179 - val_accuracy: 0.7208\n","Epoch 7/10\n","281/281 [==============================] - 6s 20ms/step - loss: 0.6934 - accuracy: 0.8228 - val_loss: 1.3208 - val_accuracy: 0.7262\n","Epoch 8/10\n","281/281 [==============================] - 5s 19ms/step - loss: 0.6023 - accuracy: 0.8446 - val_loss: 1.3585 - val_accuracy: 0.7262\n","Epoch 9/10\n","281/281 [==============================] - 5s 19ms/step - loss: 0.5269 - accuracy: 0.8616 - val_loss: 1.4033 - val_accuracy: 0.7382\n","Epoch 10/10\n","281/281 [==============================] - 6s 20ms/step - loss: 0.4769 - accuracy: 0.8731 - val_loss: 1.4522 - val_accuracy: 0.7382\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8fdabe4c90>"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"EBZtuDJsM3mK"},"source":[""],"execution_count":null,"outputs":[]}]}