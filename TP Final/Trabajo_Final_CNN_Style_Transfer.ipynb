{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCY6UbkkI9_N"
   },
   "source": [
    "# Style Transfer\n",
    "\n",
    "<img src=\"https://i0.wp.com/chelseatroy.com/wp-content/uploads/2018/12/neural_style_transfer.png?resize=768%2C311&ssl=1\">\n",
    "\n",
    "La idea de este trabajo final es reproducir el siguiente paper:\n",
    "\n",
    "https://arxiv.org/pdf/1508.06576.pdf\n",
    "\n",
    "El objetivo es transferir el estilo de una imagen dada a otra imagen distinta. \n",
    "\n",
    "Como hemos visto en clase, las primeras capas de una red convolucional se activan ante la presencia de ciertos patrones vinculados a detalles muy pequeños.\n",
    "\n",
    "A medida que avanzamos en las distintas capas de una red neuronal convolucional, los filtros se van activando a medida que detectan patrones de formas cada vez mas complejos.\n",
    "\n",
    "Lo que propone este paper es asignarle a la activación de las primeras capas de una red neuronal convolucional (por ejemplo VGG19) la definición del estilo y a la activación de las últimas capas de la red neuronal convolucional, la definición del contenido.\n",
    "\n",
    "La idea de este paper es, a partir de dos imágenes (una que aporte el estilo y otra que aporte el contenido) analizar cómo es la activación de las primeras capas para la imagen que aporta el estilo y cómo es la activación de las últimas capas de la red convolucional para la imagen que aporta el contenido. A partir de esto se intentará sintetizar una imagen que active los filtros de las primeras capas que se activaron con la imagen que aporta el estilo y los filtros de las últimas capas que se activaron con la imagen que aporta el contenido.\n",
    "\n",
    "A este procedimiento se lo denomina neural style transfer.\n",
    "\n",
    "# En este trabajo se deberá leer el paper mencionado y en base a ello, entender la implementación que se muestra a continuación y contestar preguntas sobre la misma.\n",
    "\n",
    "# Una metodología posible es hacer una lectura rápida del paper (aunque esto signifique no entender algunos detalles del mismo) y luego ir analizando el código y respondiendo las preguntas. A medida que se planteen las preguntas, volviendo a leer secciones específicas del paper terminará de entender los detalles que pudieran haber quedado pendientes.\n",
    "\n",
    "Lo primero que haremos es cargar dos imágenes, una que aporte el estilo y otra que aporte el contenido. A tal fin utilizaremos imágenes disponibles en la web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "kyHsa2t0SxZi",
    "outputId": "e72fcf52-62ed-42f1-f64e-cdb05d049797",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-31 22:58:05--  https://upload.wikimedia.org/wikipedia/commons/5/52/La_noche_estrellada1.jpg\n",
      "Resolving upload.wikimedia.org (upload.wikimedia.org)... 208.80.154.240\n",
      "Connecting to upload.wikimedia.org (upload.wikimedia.org)|208.80.154.240|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 223725 (218K) [image/jpeg]\n",
      "Saving to: ‘La_noche_estrellada1.jpg.4’\n",
      "\n",
      "La_noche_estrellada 100%[===================>] 218.48K   332KB/s    in 0.7s    \n",
      "\n",
      "2022-03-31 22:58:06 (332 KB/s) - ‘La_noche_estrellada1.jpg.4’ saved [223725/223725]\n",
      "\n",
      "--2022-03-31 22:58:06--  https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Neckarfront_T%C3%BCbingen_Mai_2017.jpg/775px-Neckarfront_T%C3%BCbingen_Mai_2017.jpg\n",
      "Resolving upload.wikimedia.org (upload.wikimedia.org)... 208.80.154.240\n",
      "Connecting to upload.wikimedia.org (upload.wikimedia.org)|208.80.154.240|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 153015 (149K) [image/jpeg]\n",
      "Saving to: ‘775px-Neckarfront_Tübingen_Mai_2017.jpg.4’\n",
      "\n",
      "775px-Neckarfront_T 100%[===================>] 149.43K   260KB/s    in 0.6s    \n",
      "\n",
      "2022-03-31 22:58:08 (260 KB/s) - ‘775px-Neckarfront_Tübingen_Mai_2017.jpg.4’ saved [153015/153015]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imagen para estilo\n",
    "!wget https://upload.wikimedia.org/wikipedia/commons/5/52/La_noche_estrellada1.jpg\n",
    "\n",
    "# Imagen para contenido\n",
    "!wget https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Neckarfront_T%C3%BCbingen_Mai_2017.jpg/775px-Neckarfront_T%C3%BCbingen_Mai_2017.jpg\n",
    "\n",
    "# Creamos el directorio para los archivos de salida\n",
    "#!mkdir /content/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "id": "NIxH20o2eFoc",
    "outputId": "4785bcbb-4070-4e68-c2b5-4a1dfdccbad2"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "import numpy as np\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "from keras.applications import vgg19\n",
    "from keras import backend as K\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "#print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iLkV1bnFl_tK"
   },
   "outputs": [],
   "source": [
    "# Definimos las imagenes que vamos a utilizar, y el directorio de salida\n",
    "\n",
    "base_image_path = Path(\"./775px-Neckarfront_Tübingen_Mai_2017.jpg\")\n",
    "style_reference_image_path = Path(\"./La_noche_estrellada1.jpg\")\n",
    "result_prefix = Path(\"./content/output\")\n",
    "iterations = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gz2PeGfpeYzj"
   },
   "source": [
    "# 1) En base a lo visto en el paper ¿Qué significan los parámetros definidos en la siguiente celda?\n",
    "\n",
    "Respuesta:\n",
    "- Los parametros style_weight y content_weight representan a alfa y beta respectivamente en la loss function. La magnitud de cada uno indica el enfasis que tendra la imagen de salida. A mayor style_weight tendremos una imagen de salida con mas enfasis en el estilo y no sera tan evidente la imagen de partida. \n",
    "- El parametro total_variation_weight indica la relacion entre content_weight/style_weight, cuanto mas alta sea la relacion mayor enfasis tendra la imagen de salida en la imagen de partida y menos en el estilo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "P9Dt3aaEmJWS"
   },
   "outputs": [],
   "source": [
    "total_variation_weight = 0.1\n",
    "style_weight = 10\n",
    "content_weight = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CQQJOhCVuse6"
   },
   "outputs": [],
   "source": [
    "# Definimos el tamaño de las imágenes a utilizar\n",
    "width, height = load_img(base_image_path).size\n",
    "img_nrows = 400\n",
    "img_ncols = int(width * img_nrows / height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gg2ct-8agm1E"
   },
   "source": [
    "# 2) Explicar qué hace la siguiente celda. En especial las últimas dos líneas de la función antes del return. ¿Por qué?\n",
    "\n",
    "Ayuda: https://keras.io/applications/\n",
    "\n",
    "Respuesta:\n",
    "- La funcion redimensiona y convierte la imagen un tensor. Utiliza VGG19 para convertir la imagen de RGB a BGR y centra cada canal de color en cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tAkljg4zuzYd"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(img_nrows, img_ncols))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg19.preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTf0YDSagt10"
   },
   "source": [
    "# 3) Habiendo comprendido lo que hace la celda anterior, explique de manera muy concisa qué hace la siguiente celda. ¿Qué relación tiene con la celda anterior?\n",
    "\n",
    "Respuesta:\n",
    "- Convierte el tensor en una imagen, pasandando de BGR a RGB y removiendo el centrado en cero de los canales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "y5LaTrsAu14z"
   },
   "outputs": [],
   "source": [
    "def deprocess_image(x):\n",
    "    x = x.reshape((img_nrows, img_ncols, 3))\n",
    "    # Remove zero-center by mean pixel\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    # 'BGR'->'RGB'\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "HYNio09mu4S3"
   },
   "outputs": [],
   "source": [
    "# get tensor representations of our images\n",
    "# K.variable convierte un numpy array en un tensor, para \n",
    "base_image = K.variable(preprocess_image(base_image_path))\n",
    "style_reference_image = K.variable(preprocess_image(style_reference_image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "a1Lbw02Uu--o",
    "outputId": "6cc926fa-55af-43fa-fe91-3b68c0910502"
   },
   "outputs": [],
   "source": [
    "combination_image = K.placeholder((1, img_nrows, img_ncols, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJEi0YI3Uzrm"
   },
   "source": [
    "Aclaración:\n",
    "\n",
    "La siguiente celda sirve para procesar las tres imagenes (contenido, estilo y salida) en un solo batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gGO_jGFfvEbF"
   },
   "outputs": [],
   "source": [
    "# combine the 3 images into a single Keras tensor\n",
    "input_tensor = K.concatenate([base_image,\n",
    "                              style_reference_image,\n",
    "                              combination_image], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "tdG59VRavHGB",
    "outputId": "a133befb-68d1-4c51-99e6-417c1103f726"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "# build the VGG19 network with our 3 images as input\n",
    "# the model will be loaded with pre-trained ImageNet weights\n",
    "model = vgg19.VGG19(input_tensor=input_tensor,\n",
    "                    weights='imagenet', include_top=False)\n",
    "print('Model loaded.')\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70-vs_jZkKVc"
   },
   "source": [
    "# 4) En la siguientes celdas:\n",
    "\n",
    "- ¿Qué es la matriz de Gram?¿Para qué se usa?\n",
    "- ¿Por qué se permutan las dimensiones de x?\n",
    "\n",
    "Respuesta: \n",
    "- La matriz Gram el producto punto entre todos los vectores del mapa de caracteristicas aplanados.Indica donde se encuentra la informacion fundamental de cada caracteristica y la relacion entre estas.  \n",
    "- Se permutan las dimensiones para que la 3ra pase a ser la 1er dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "K1FODPATvJ1k"
   },
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
    "    gram = K.dot(features, K.transpose(features))\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBQkKFY0Rbx-"
   },
   "source": [
    "# 5) Losses:\n",
    "\n",
    "Explicar qué mide cada una de las losses en las siguientes tres celdas.\n",
    "\n",
    "Rta:\n",
    "- style_loss: valor de la distancia entre el estilo (representada en la Matriz Gram) de la imagen de estilo con el resultado.\n",
    "- content_loss: valor de la distancia entre la imagen de entrada con la imagen resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1-Gt0ahWvN6q"
   },
   "outputs": [],
   "source": [
    "def style_loss(style, combination):\n",
    "    assert K.ndim(style) == 3\n",
    "    assert K.ndim(combination) == 3\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    channels = 3\n",
    "    size = img_nrows * img_ncols\n",
    "    return K.sum(K.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "XCqnju5RvQCo"
   },
   "outputs": [],
   "source": [
    "def content_loss(base, combination):\n",
    "    return K.sum(K.square(combination - base))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "udEp5h31vRnY"
   },
   "outputs": [],
   "source": [
    "def total_variation_loss(x):\n",
    "    assert K.ndim(x) == 4\n",
    "    a = K.square(\n",
    "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n",
    "    b = K.square(\n",
    "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n",
    "    return K.sum(K.pow(a + b, 1.25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "-65vcinbvTZ0"
   },
   "outputs": [],
   "source": [
    "# Armamos la loss total\n",
    "loss = K.variable(0.0)\n",
    "layer_features = outputs_dict['block5_conv2']\n",
    "base_image_features = layer_features[0, :, :, :]\n",
    "combination_features = layer_features[2, :, :, :]\n",
    "loss = loss + content_weight * content_loss(base_image_features,\n",
    "                                            combination_features)\n",
    "\n",
    "feature_layers = ['block1_conv1', 'block2_conv1',\n",
    "                  'block3_conv1', 'block4_conv1',\n",
    "                  'block5_conv1']\n",
    "for layer_name in feature_layers:\n",
    "    layer_features = outputs_dict[layer_name]\n",
    "    style_reference_features = layer_features[1, :, :, :] \n",
    "    combination_features = layer_features[2, :, :, :]\n",
    "    sl = style_loss(style_reference_features, combination_features)\n",
    "    loss = loss + (style_weight / len(feature_layers)) * sl\n",
    "loss = loss + total_variation_weight * total_variation_loss(combination_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "id": "pbz4n1OhvV2K",
    "outputId": "c2b208c6-7ddd-4a40-eeda-525f0809b963"
   },
   "outputs": [],
   "source": [
    "grads = K.gradients(loss, combination_image)\n",
    "\n",
    "\n",
    "outputs = [loss]\n",
    "if isinstance(grads, (list, tuple)):\n",
    "    outputs += grads\n",
    "else:\n",
    "    outputs.append(grads)\n",
    "\n",
    "f_outputs = K.function([combination_image], outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JbydbOaVcvU"
   },
   "source": [
    "# 6) Explique el propósito de las siguientes tres celdas. ¿Qué hace la función fmin_l_bfgs_b? ¿En qué se diferencia con la implementación del paper? ¿Se puede utilizar alguna alternativa?\n",
    "\n",
    "Respuesta:\n",
    "- En estas celdas se obtiene el valor de la loss y el gradiente para una imagen de entrada. Estos valores son iterados hasta encontrar un minimo, utilizando la funcion fmin_l_bfgs_b como optimizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "zVE1_qemvZeN"
   },
   "outputs": [],
   "source": [
    "def eval_loss_and_grads(x):\n",
    "    x = x.reshape((1, img_nrows, img_ncols, 3))\n",
    "    outs = f_outputs([x])\n",
    "    loss_value = outs[0]\n",
    "    if len(outs[1:]) == 1:\n",
    "        grad_values = outs[1].flatten().astype('float64')\n",
    "    else:\n",
    "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
    "    return loss_value, grad_values\n",
    "\n",
    "# this Evaluator class makes it possible\n",
    "# to compute loss and gradients in one pass\n",
    "# while retrieving them via two separate functions,\n",
    "# \"loss\" and \"grads\". This is done because scipy.optimize\n",
    "# requires separate functions for loss and gradients,\n",
    "# but computing them separately would be inefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Qbl9roIgvdb1"
   },
   "outputs": [],
   "source": [
    "class Evaluator(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sb0yOEl-WOE6"
   },
   "source": [
    "# 7) Ejecute la siguiente celda y observe las imágenes de salida en cada iteración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "n31YBwCVvhAI",
    "outputId": "4c1bf03c-9d66-48ea-93f2-4489fc20beaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of iteration 0\n",
      "Current loss value: 13272484000.0\n",
      "Image saved as content/output/output_at_iteration_0.png\n",
      "Iteration 0 completed in 112s\n",
      "Start of iteration 1\n",
      "Current loss value: 6390965000.0\n",
      "Image saved as content/output/output_at_iteration_1.png\n",
      "Iteration 1 completed in 106s\n",
      "Start of iteration 2\n",
      "Current loss value: 4375173000.0\n",
      "Image saved as content/output/output_at_iteration_2.png\n",
      "Iteration 2 completed in 103s\n",
      "Start of iteration 3\n",
      "Current loss value: 3297279200.0\n",
      "Image saved as content/output/output_at_iteration_3.png\n",
      "Iteration 3 completed in 103s\n",
      "Start of iteration 4\n",
      "Current loss value: 2656761300.0\n",
      "Image saved as content/output/output_at_iteration_4.png\n",
      "Iteration 4 completed in 107s\n",
      "Start of iteration 5\n",
      "Current loss value: 2256721000.0\n",
      "Image saved as content/output/output_at_iteration_5.png\n",
      "Iteration 5 completed in 118s\n",
      "Start of iteration 6\n",
      "Current loss value: 2039802000.0\n",
      "Image saved as content/output/output_at_iteration_6.png\n",
      "Iteration 6 completed in 102s\n",
      "Start of iteration 7\n",
      "Current loss value: 1901083600.0\n",
      "Image saved as content/output/output_at_iteration_7.png\n",
      "Iteration 7 completed in 102s\n",
      "Start of iteration 8\n",
      "Current loss value: 1797442600.0\n",
      "Image saved as content/output/output_at_iteration_8.png\n",
      "Iteration 8 completed in 102s\n",
      "Start of iteration 9\n",
      "Current loss value: 1684671700.0\n",
      "Image saved as content/output/output_at_iteration_9.png\n",
      "Iteration 9 completed in 102s\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator()\n",
    "\n",
    "# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
    "# so as to minimize the neural style loss\n",
    "x = preprocess_image(base_image_path)\n",
    "\n",
    "for i in range(iterations):\n",
    "    print('Start of iteration', i)\n",
    "    start_time = time.time()\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
    "                                     fprime=evaluator.grads, maxfun=20)\n",
    "    print('Current loss value:', min_val)\n",
    "    # save current generated image\n",
    "    img = deprocess_image(x.copy())\n",
    "    fname = result_prefix / ('output_at_iteration_%d.png' % i)\n",
    "    save_img(fname, img)\n",
    "    end_time = time.time()\n",
    "    print('Image saved as', fname)\n",
    "    print('Iteration %d completed in %ds' % (i, end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkiJtofbWWy1"
   },
   "source": [
    "# 8) Generar imágenes para distintas combinaciones de pesos de las losses. Explicar las diferencias. (Adjuntar las imágenes generadas como archivos separados.)\n",
    "\n",
    "Respuesta:\n",
    "- Las imagenes se generaron con los siguientes parametros:\n",
    "    - total_variation_weight = 0.1\n",
    "    - style_weight = 10\n",
    "    - content_weight = 1\n",
    "\n",
    "- El efecto en relacion al original (style_weight = 1 y content_weight = 10) es que el resultado tiene un mayor predominio del estilo que del contenido.\n",
    "\n",
    "\n",
    "# 9) Cambiar las imágenes de contenido y estilo por unas elegidas por usted. Adjuntar el resultado.\n",
    "\n",
    "Respuesta:\n",
    "- Ver carpeta \"Resultado Ejercicio 9\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Trabajo Final CNN - Style Transfer.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
